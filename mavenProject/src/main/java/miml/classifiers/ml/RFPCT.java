package miml.classifiers.ml;

import java.io.*;
import java.nio.file.Paths;

import mulan.classifier.MultiLabelLearnerBase;
import mulan.classifier.MultiLabelOutput;
import mulan.data.MultiLabelInstances;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.TechnicalInformation;
import weka.filters.Filter;
import weka.filters.unsupervised.instance.SparseToNonSparse;

public class RFPCT extends MultiLabelLearnerBase {

    /** For serialization. */
    private static final long serialVersionUID = 1L;
    /** The directory where all temporary files needed or generated by CLUS library are written. */
    protected String clusWorkingDir;
    /** The dataset name that will be used for training, test and settings files. */
    protected String datasetName;
    /** Path to the settings file. */
    protected String settingsFilePath;
    /** The number of random trees in the ensemble. */
    private int numTrees;
    /** A seed for randomization. */
    private long seed;
    /** Whether numeric attributes are normalized. By default, false. */
    private boolean normalize;

    /**
     * Constructor.
     *
     * @param clusWorkingDir  The directory where all temporary files needed or
     *                        generated by CLUS library are written. This name needs
     *                        a final slash separator i.e. "clusFolder\"
     * @param clusDatasetName The dataset name that will be used for training, test
     *                        and settings files.
     * @param numTrees        the number of trees.
     * @param seed            The seed of random generator.
     * @param normalize       Whether numeric attributes are normalized.
     */
    public RFPCT(String clusWorkingDir, String clusDatasetName, int numTrees, long seed, boolean normalize) {
        this.clusWorkingDir = clusWorkingDir;
        this.datasetName = clusDatasetName;
        this.numTrees = numTrees;
        this.seed = seed;
        this.normalize = normalize;
    }

    /**
     * This method does the following:
     * Creates a working directory for the CLUS library
     * Makes the supplied training set CLUS compliant and copies it to the working directory
     * Modifies the File, TestSet and Target lines of the settings file to the appropriate values
     * @param trainingSet the training data set
     * @throws Exception
     */
    @Override
    protected void buildInternal(MultiLabelInstances trainingSet) throws Exception {
        // create the CLUS working directory if it does not exist
        File theDir = new File(clusWorkingDir);
        if (!theDir.exists()) {
            System.out.println("Creating CLUS working directory: " + clusWorkingDir);
            boolean result = theDir.mkdir();
            if (result) {
                System.out.println("CLUS working directory created");
            }
        }

        // transform the supplied MultilabelInstances object in an arff formated file (accepted by CLUS) and write the file in the working directory with the appropriate name
        makeClusCompliant(trainingSet, Paths.get(clusWorkingDir, datasetName + "-train.arff").toString());

        if (settingsFilePath != null) {
            // modify the File, TestSet and Target lines of the settings file to the appropriate values
            BufferedReader in = new BufferedReader(new FileReader(settingsFilePath));
            StringBuilder settings = new StringBuilder();
            String line;
            while ((line = in.readLine()) != null) {
                if (line.startsWith("File")) {
                    settings.append("File = ").append(Paths.get(clusWorkingDir, datasetName + "-train.arff\n"));
                } else if (line.startsWith("TestSet")) {
                    settings.append("TestSet = ").append(Paths.get(clusWorkingDir, datasetName + "-test.arff\n"));
                } else if (line.startsWith("Target")) {
                    settings.append("Target = ");
                    for (int i = 0; i < numLabels - 1; i++) {
                        // all targets except last
                        settings.append((labelIndices[i] + 1)).append(",");
                    }
                    // last target
                    settings.append((labelIndices[numLabels - 1] + 1)).append("\n");
                } else {
                    settings.append(line).append("\n");
                }
            }
            in.close();

            BufferedWriter out = new BufferedWriter(
                    new FileWriter(Paths.get(clusWorkingDir, datasetName + "-train.s").toString())
            );
            out.write(settings.toString());
            out.close();
        }
        createSettingsFile();
    }

    /**
     * This method exists so that CLUSWrapperClassification can extend MultiLabelLearnerBase. Also helps the
     * Evaluator to determine the type of the MultiLabelOutput and thus prepare the appropriate evaluation
     * measures.
     */
    @Override
    protected MultiLabelOutput makePredictionInternal(Instance instance) throws Exception {
        double[] confidences = new double[numLabels];
        return new MultiLabelOutput(confidences, 0.5);

    }

    @Override
    public TechnicalInformation getTechnicalInformation() {
        return null;
    }

    /**
     * Takes a dataset as a MultiLabelInstances object and writes an arff file that is compliant with CLUS.
     *
     * @param mlDataset the dataset as a MultiLabelInstances object
     * @param fileName the name of the generated arff file
     * @throws Exception Potential exception thrown. To be handled in an upper level.
     */
    public static void makeClusCompliant(MultiLabelInstances mlDataset, String fileName) throws Exception {
        BufferedWriter out = new BufferedWriter(new FileWriter(fileName));

        // the file will be written in the datasetPath directory
        // Instances dataset = mlDataset.getDataSet();
        // any changes are applied to a copy of the original dataset
        Instances dataset = new Instances(mlDataset.getDataSet());
        SparseToNonSparse stns = new SparseToNonSparse(); // new instance of filter
        stns.setInputFormat(dataset); // inform filter about dataset **AFTER** setting options
        Instances nonSparseDataset = Filter.useFilter(dataset, stns); // apply filter

        String header = new Instances(nonSparseDataset, 0).toString();
        // preprocess the header
        // remove ; characters and truncate long attribute names
        String[] headerLines = header.split("\n");
        for (int i = 0; i < headerLines.length; i++) {
            if (headerLines[i].startsWith("@attribute")) {
                headerLines[i] = headerLines[i].replaceAll(";", "SEMI_COLON");
                String originalAttributeName = headerLines[i].split(" ")[1];
                String newAttributeName = originalAttributeName;
                if (originalAttributeName.length() > 30) {
                    newAttributeName = originalAttributeName.substring(0, 30) + "..";
                }
                out.write(headerLines[i].replace(originalAttributeName, newAttributeName) + "\n");
            } else {
                out.write(headerLines[i] + "\n");
            }
        }
        for (int i = 0; i < nonSparseDataset.numInstances(); i++) {
            if (i % 100 == 0) {
                out.flush();
            }
            out.write(nonSparseDataset.instance(i) + "\n");
        }
        out.close();
    }

    /**
     * This method creates a CLUS settings file that corresponds to the MORF
     * algorithm and writes it in clusWorkingDir.
     *
     * @throws Exception Potential exception thrown. To be handled in an upper
     *                   level.
     */
    private void createSettingsFile() throws Exception {
        BufferedWriter out = new BufferedWriter(
                new FileWriter(Paths.get(clusWorkingDir, datasetName + "-train.s").toString())
        );
        out.write("[General]\nVerbose = 0\n");
        out.write("RandomSeed = " + seed + "\n\n[Data]\n");
        out.write("File = " + clusWorkingDir + "/" + datasetName + "-train.arff" + "\n");
        out.write("TestSet = " + clusWorkingDir + "/" + datasetName + "-test.arff" + "\n");
        out.write("\n[Attributes]\n");
        out.write("Target = ");
        for (int i = 0; i < numLabels - 1; i++) {// all targets except last
            out.write((labelIndices[i] + 1) + ",");
        }
        out.write((labelIndices[numLabels - 1] + 1) + "\n"); // last target
        // if (normalize)
        out.write("Weights = Normalize\n");
        out.write("\n");
        out.write("[Ensemble]\nIterations = " + numTrees + "\n");
        out.write("EnsembleMethod = RForest\n\n[Output]\nWritePredictions = Test\n");
        out.close();
    }

    public void setClusWorkingDir(String clusWorkingDir) {
        this.clusWorkingDir = clusWorkingDir;
    }
    public void setDatasetName(String datasetName) {
        this.datasetName = datasetName;
    }
    public void setNumTrees(int numTrees) {
        this.numTrees = numTrees;
    }
    public void setSeed(long seed) {
        this.seed = seed;
    }
    public void setNormalize(boolean normalize) {
        this.normalize = normalize;
    }
}
